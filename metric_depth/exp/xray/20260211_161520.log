xFormers not available
xFormers not available
[2026-02-11 16:15:21,409][    INFO] {'bs': 1,
 'dataset': 'xray',
 'encoder': 'vitl',
 'epochs': 120,
 'img_size': 518,
 'lr': 5e-06,
 'max_depth': 1000.0,
 'min_depth': 0.001,
 'pretrained_from': '../checkpoints/depth_anything_v2_vitl.pth',
 'save_path': 'exp/xray'}

[2026-02-11 16:15:24,591][    INFO] ===========> Epoch: 0/120, d1: 0.000, d2: 0.000, d3: 0.000
[2026-02-11 16:15:24,591][    INFO] ===========> Epoch: 0/120, abs_rel: 100.000, sq_rel: 100.000, rmse: 100.000, rmse_log: 100.000, log10: 100.000, silog: 100.000
[2026-02-11 16:15:27,113][    INFO] Iter: 0/8800, LR: 0.0000050, Loss: 0.190
[2026-02-11 16:16:20,529][    INFO] Iter: 100/8800, LR: 0.0000050, Loss: 0.092
[2026-02-11 16:17:11,431][    INFO] Iter: 200/8800, LR: 0.0000050, Loss: 0.202
[2026-02-11 16:18:01,782][    INFO] Iter: 300/8800, LR: 0.0000050, Loss: 0.038
[2026-02-11 16:18:52,363][    INFO] Iter: 400/8800, LR: 0.0000050, Loss: 0.097
[2026-02-11 16:19:43,128][    INFO] Iter: 500/8800, LR: 0.0000050, Loss: 0.080
[2026-02-11 16:20:33,921][    INFO] Iter: 600/8800, LR: 0.0000050, Loss: 0.059
[2026-02-11 16:21:24,751][    INFO] Iter: 700/8800, LR: 0.0000050, Loss: 0.068
[2026-02-11 16:22:15,606][    INFO] Iter: 800/8800, LR: 0.0000050, Loss: 0.047
[2026-02-11 16:23:06,642][    INFO] Iter: 900/8800, LR: 0.0000050, Loss: 0.068
[2026-02-11 16:23:57,589][    INFO] Iter: 1000/8800, LR: 0.0000050, Loss: 0.061
[2026-02-11 16:24:48,455][    INFO] Iter: 1100/8800, LR: 0.0000050, Loss: 0.116
[2026-02-11 16:25:39,461][    INFO] Iter: 1200/8800, LR: 0.0000050, Loss: 0.095
[2026-02-11 16:26:30,393][    INFO] Iter: 1300/8800, LR: 0.0000050, Loss: 0.040
[2026-02-11 16:27:21,333][    INFO] Iter: 1400/8800, LR: 0.0000050, Loss: 0.076
[2026-02-11 16:28:12,283][    INFO] Iter: 1500/8800, LR: 0.0000050, Loss: 0.096
[2026-02-11 16:29:03,276][    INFO] Iter: 1600/8800, LR: 0.0000050, Loss: 0.062
[2026-02-11 16:29:54,191][    INFO] Iter: 1700/8800, LR: 0.0000050, Loss: 0.073
[2026-02-11 16:30:45,113][    INFO] Iter: 1800/8800, LR: 0.0000050, Loss: 0.222
[2026-02-11 16:31:35,996][    INFO] Iter: 1900/8800, LR: 0.0000050, Loss: 0.081
[2026-02-11 16:32:26,952][    INFO] Iter: 2000/8800, LR: 0.0000050, Loss: 0.091
[2026-02-11 16:33:17,883][    INFO] Iter: 2100/8800, LR: 0.0000050, Loss: 0.102
[2026-02-11 16:34:08,758][    INFO] Iter: 2200/8800, LR: 0.0000050, Loss: 0.034
[2026-02-11 16:34:59,722][    INFO] Iter: 2300/8800, LR: 0.0000050, Loss: 0.078
[2026-02-11 16:35:50,773][    INFO] Iter: 2400/8800, LR: 0.0000050, Loss: 0.045
[2026-02-11 16:36:41,879][    INFO] Iter: 2500/8800, LR: 0.0000050, Loss: 0.049
[2026-02-11 16:37:32,980][    INFO] Iter: 2600/8800, LR: 0.0000050, Loss: 0.112
[2026-02-11 16:38:23,967][    INFO] Iter: 2700/8800, LR: 0.0000050, Loss: 0.026
[2026-02-11 16:39:15,042][    INFO] Iter: 2800/8800, LR: 0.0000050, Loss: 0.029
[2026-02-11 16:40:06,105][    INFO] Iter: 2900/8800, LR: 0.0000050, Loss: 0.128
[2026-02-11 16:40:57,143][    INFO] Iter: 3000/8800, LR: 0.0000050, Loss: 0.052
[2026-02-11 16:41:48,177][    INFO] Iter: 3100/8800, LR: 0.0000050, Loss: 0.074
[2026-02-11 16:42:39,289][    INFO] Iter: 3200/8800, LR: 0.0000050, Loss: 0.073
[2026-02-11 16:43:30,370][    INFO] Iter: 3300/8800, LR: 0.0000050, Loss: 0.105
[2026-02-11 16:44:21,571][    INFO] Iter: 3400/8800, LR: 0.0000050, Loss: 0.071
[2026-02-11 16:45:12,725][    INFO] Iter: 3500/8800, LR: 0.0000050, Loss: 0.085
[2026-02-11 16:46:03,182][    INFO] Iter: 3600/8800, LR: 0.0000050, Loss: 0.075
[2026-02-11 16:46:53,395][    INFO] Iter: 3700/8800, LR: 0.0000050, Loss: 0.110
[2026-02-11 16:47:43,526][    INFO] Iter: 3800/8800, LR: 0.0000050, Loss: 0.037
[2026-02-11 16:48:33,497][    INFO] Iter: 3900/8800, LR: 0.0000050, Loss: 0.044
[2026-02-11 16:49:23,480][    INFO] Iter: 4000/8800, LR: 0.0000050, Loss: 0.068
[2026-02-11 16:50:13,449][    INFO] Iter: 4100/8800, LR: 0.0000050, Loss: 0.052
[2026-02-11 16:51:03,445][    INFO] Iter: 4200/8800, LR: 0.0000050, Loss: 0.124
[2026-02-11 16:51:53,428][    INFO] Iter: 4300/8800, LR: 0.0000050, Loss: 0.021
[2026-02-11 16:52:43,401][    INFO] Iter: 4400/8800, LR: 0.0000050, Loss: 0.046
[2026-02-11 16:53:33,985][    INFO] Iter: 4500/8800, LR: 0.0000050, Loss: 0.064
[2026-02-11 16:54:24,925][    INFO] Iter: 4600/8800, LR: 0.0000050, Loss: 0.037
[2026-02-11 16:55:16,682][    INFO] Iter: 4700/8800, LR: 0.0000050, Loss: 0.067
[2026-02-11 16:56:07,974][    INFO] Iter: 4800/8800, LR: 0.0000050, Loss: 0.054
[2026-02-11 16:56:59,498][    INFO] Iter: 4900/8800, LR: 0.0000050, Loss: 0.032
[2026-02-11 16:57:50,726][    INFO] Iter: 5000/8800, LR: 0.0000050, Loss: 0.111
[2026-02-11 16:58:41,193][    INFO] Iter: 5100/8800, LR: 0.0000050, Loss: 0.047
[2026-02-11 16:59:31,962][    INFO] Iter: 5200/8800, LR: 0.0000050, Loss: 0.066
[2026-02-11 17:00:23,050][    INFO] Iter: 5300/8800, LR: 0.0000050, Loss: 0.064
[2026-02-11 17:01:14,263][    INFO] Iter: 5400/8800, LR: 0.0000050, Loss: 0.091
[2026-02-11 17:02:04,775][    INFO] Iter: 5500/8800, LR: 0.0000050, Loss: 0.080
[2026-02-11 17:02:55,351][    INFO] Iter: 5600/8800, LR: 0.0000050, Loss: 0.072
[2026-02-11 17:03:45,683][    INFO] Iter: 5700/8800, LR: 0.0000050, Loss: 0.077
